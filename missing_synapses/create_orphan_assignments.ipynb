{
 "metadata": {
  "name": "",
  "signature": "sha256:4346a45a4e9dd3c044deea2e4e61c686554e71c1140439dfbd2a35c356e57592"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Create Orphan Assignments for Forgotten Border Synapses\n",
      "\n",
      "Ting generated a list of synapse bodies less than 100,000 voxels that touch but do not cross a substack boundary.  These bodies were not traced previously but should have been.\n",
      "\n",
      "###Input\n",
      "\n",
      "* Ting's list of of unexamined boundaries (first body in Ting's list represents the unexamined body)\n",
      "* The number of orphans desired for each proofreader task\n",
      "* The desired output directory\n",
      "\n",
      "###Output\n",
      "\n",
      "* Print the number of orphans\n",
      "* Output the orphan assignments in the desired location\n",
      "* Assume that the unextended stack will be used"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# function that generates orphan assignment\n",
      "def create_orphan_assignments(assignment_size, orphan_file, output_dir):\n",
      "    import os\n",
      "    import json\n",
      "    import random\n",
      "    \n",
      "    try:\n",
      "        os.makedirs(output_dir)\n",
      "    except OSError:\n",
      "        pass    \n",
      "    \n",
      "    data = json.load(open(orphan_file))\n",
      "    \n",
      "    goodbodies = set()\n",
      "    body_locations = {}\n",
      "    \n",
      "    # find all the good bodies (might be possible to have a body over 100000 that doesn't cross but redundancy is okay)\n",
      "    for body in data[\"Bodies\"]:\n",
      "        body_locations[body[\"id\"]] = body[\"marker\"]\n",
      "        if body[\"cross_substack\"]:\n",
      "            if body[\"num_synapses\"] > 0 or body[\"size\"] >= 100000:\n",
      "                goodbodies.add(body[\"id\"])\n",
      "\n",
      "    body_list = []\n",
      "\n",
      "    # go through all edges and grab orphans\n",
      "    for edge in data[\"Overlap\"]:\n",
      "        id1 = edge[\"id1\"]\n",
      "        id2 = edge[\"id2\"]\n",
      "\n",
      "        # it is okay to have duplicate edges since candidate edge might not be correct\n",
      "        # if the edge wasn't examined before by focused stitch (or bookmark if given a bad sight) -- add to orphan list\n",
      "        if id2 not in goodbodies:\n",
      "            body_list.append(body_locations[id1])\n",
      "\n",
      "    random.shuffle(body_list)\n",
      "\n",
      "    # boilerplate for orphan json output\n",
      "    json_out = {}\n",
      "    json_out[\"metadata\"] = {\"description\": \"point list\", \"file version\": 1}\n",
      "    json_out[\"data\"] = {}\n",
      "    json_out[\"data\"][\"threshold\"] = 100000\n",
      "    json_out[\"data\"][\"threshold comparison\"] = \"target\"\n",
      "\n",
      "    # break body list into several assignments\n",
      "    num_assignments = len(body_list) / assignment_size + 1\n",
      "    for assign in range(0, num_assignments):\n",
      "        start = assign * assignment_size\n",
      "        finish = start + assignment_size\n",
      "        if finish > len(body_list):\n",
      "            finish = len(body_list)\n",
      "\n",
      "        new_body_list = []\n",
      "        for bodynum in range(start, finish):\n",
      "            new_body_list.append(body_list[bodynum])\n",
      "\n",
      "        json_out[\"data\"][\"point list\"] = new_body_list\n",
      "\n",
      "        fout = open(output_dir + \"/%d.json\" % assign, 'w')\n",
      "        fout.write(json.dumps(json_out, indent=4))\n",
      "    \n",
      "    print \"Assignment size: \", assignment_size\n",
      "    print \"Orphan file used: \", orphan_file\n",
      "    print \"Output directory: \", output_dir\n",
      "    print \"Number of assignments: \", num_assignments\n",
      "    print \"Number of total orphans: \", len(body_list)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# common prefix for data files\n",
      "prefix=\"/groups/flyem/data/medulla-FIB-Z1211-25-production/align2/base_stacks/shinya1-13_20140516\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# create random orphan assignments with 200 per file\n",
      "create_orphan_assignments(200, prefix + \"/focused-debug/input/input.json\", prefix + \"/orphan-assignments\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Assignment size:  200\n",
        "Orphan file used:  /groups/flyem/data/medulla-FIB-Z1211-25-production/align2/base_stacks/shinya1-13_20140516/focused-debug/input/input.json\n",
        "Output directory:  /groups/flyem/data/medulla-FIB-Z1211-25-production/align2/base_stacks/shinya1-13_20140516/orphan-assignments\n",
        "Number of assignments:  73\n",
        "Number of total orphans:  14544\n"
       ]
      }
     ],
     "prompt_number": 4
    }
   ],
   "metadata": {}
  }
 ]
}